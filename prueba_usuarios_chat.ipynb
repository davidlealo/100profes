{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0lAX4fgdM2sO7CqF09WTA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlealo/100profes/blob/master/prueba_usuarios_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4zgdv3iC-dq",
        "outputId": "74742d76-4f06-4da4-fef0-6f040e5bb2ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prueba de Chat con Memoria\n",
            "Ingresa tu ID de usuario (escribe 'salir' para terminar): 1\n",
            "Tú: David\n",
            "[INFO] Nueva sesión creada para el usuario: 1\n",
            "Chatbot: Hola, 1. Me dijiste: David. Es nuestra primera conversación.\n",
            "Ingresa tu ID de usuario (escribe 'salir' para terminar): 1\n",
            "Tú: David\n",
            "Chatbot: Hola, 1. Me dijiste: David. Recuerdo que también mencionaste: David.\n",
            "Ingresa tu ID de usuario (escribe 'salir' para terminar): 1\n",
            "Tú: Hola\n",
            "Chatbot: Hola, 1. Me dijiste: Hola. Recuerdo que también mencionaste: David | David.\n",
            "Ingresa tu ID de usuario (escribe 'salir' para terminar): 2\n",
            "Tú: Bea\n",
            "[INFO] Nueva sesión creada para el usuario: 2\n",
            "Chatbot: Hola, 2. Me dijiste: Bea. Es nuestra primera conversación.\n",
            "Ingresa tu ID de usuario (escribe 'salir' para terminar): salir\n"
          ]
        }
      ],
      "source": [
        "# Simulación de un chat con memoria de usuario\n",
        "\n",
        "# Memoria para almacenar el contexto por usuario (simulación en memoria)\n",
        "user_sessions = {}\n",
        "\n",
        "# Función para manejar la interacción con el usuario\n",
        "def chat_with_user(user_id, message):\n",
        "    # Recuperar el contexto del usuario si existe\n",
        "    if user_id not in user_sessions:\n",
        "        user_sessions[user_id] = {\"context\": []}\n",
        "        print(f\"[INFO] Nueva sesión creada para el usuario: {user_id}\")\n",
        "\n",
        "    context = user_sessions[user_id][\"context\"]\n",
        "\n",
        "    # Crear la respuesta basándonos en el contexto\n",
        "    response = f\"Hola, {user_id}. Me dijiste: {message}. \"\n",
        "    if context:\n",
        "        response += f\"Recuerdo que también mencionaste: {' | '.join(context)}.\"\n",
        "    else:\n",
        "        response += \"Es nuestra primera conversación.\"\n",
        "\n",
        "    # Actualizar el contexto con el mensaje actual\n",
        "    context.append(message)\n",
        "    user_sessions[user_id][\"context\"] = context\n",
        "\n",
        "    return response\n",
        "\n",
        "# Probar el sistema de chat\n",
        "print(\"Prueba de Chat con Memoria\")\n",
        "while True:\n",
        "    user_id = input(\"Ingresa tu ID de usuario (escribe 'salir' para terminar): \")\n",
        "    if user_id.lower() == \"salir\":\n",
        "        break\n",
        "    message = input(\"Tú: \")\n",
        "    response = chat_with_user(user_id, message)\n",
        "    print(f\"Chatbot: {response}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_sessions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMo2cRjBDipU",
        "outputId": "39af622b-488e-488d-b9c8-8c7322222c32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': {'context': ['David', 'David', 'Hola']}, '2': {'context': ['Bea']}}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nuevo enfoque con API DE MISTRAL\n"
      ],
      "metadata": {
        "id": "GxJwcTFFEIB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# Solicitar la API key de Mistral\n",
        "MISTRAL_API_KEY = getpass(\"Ingresa tu API key de Mistral: \")\n",
        "\n",
        "# Confirmar que la clave fue ingresada (sin mostrarla)\n",
        "if MISTRAL_API_KEY:\n",
        "    print(\"API key configurada correctamente.\")\n",
        "else:\n",
        "    print(\"No ingresaste una API key. Por favor, reinicia y vuelve a intentarlo.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7rBJQoHEKfk",
        "outputId": "d8620ba2-2c37-4e7a-c4d8-f91deadc5be4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingresa tu API key de Mistral: ··········\n",
            "API key configurada correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from flask import Flask, request, jsonify\n",
        "from threading import Thread\n",
        "from getpass import getpass\n",
        "\n",
        "# Solicitar la API key de Mistral\n",
        "MISTRAL_API_KEY = getpass(\"Ingresa tu API key de Mistral: \")\n",
        "\n",
        "if not MISTRAL_API_KEY:\n",
        "    raise ValueError(\"No se ingresó una API key. Deteniendo ejecución.\")\n",
        "\n",
        "# Simulación de sesiones en memoria\n",
        "user_sessions = {}\n",
        "\n",
        "# URL de la API de Mistral\n",
        "MISTRAL_API_URL = \"https://api.mistral.ai/v1/chat/completions\"\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "def query_mistral(prompt):\n",
        "    \"\"\"\n",
        "    Consulta la API de Mistral para generar una respuesta.\n",
        "    \"\"\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {MISTRAL_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"mistral-7b-v0.1\",  # Cambia este modelo según la documentación\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"max_tokens\": 150,\n",
        "        \"temperature\": 0.7,  # Creatividad de la respuesta\n",
        "        \"top_p\": 1.0  # Diversidad en la generación\n",
        "    }\n",
        "\n",
        "    print(\"Payload enviado:\", payload)  # Ayuda para depurar el payload enviado\n",
        "\n",
        "    try:\n",
        "        response = requests.post(MISTRAL_API_URL, json=payload, headers=headers)\n",
        "        response.raise_for_status()  # Lanza excepción para códigos de error HTTP\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        # Capturar errores HTTP o de red\n",
        "        print(\"Respuesta completa del error:\", e.response.text if e.response else \"Sin respuesta del servidor\")\n",
        "        return f\"Error al consultar la API de Mistral: {e}\"\n",
        "    except KeyError:\n",
        "        # Capturar errores si la estructura de respuesta no es la esperada\n",
        "        return \"Error: respuesta inesperada de la API.\"\n",
        "\n",
        "@app.route(\"/chat\", methods=[\"POST\"])\n",
        "def chat():\n",
        "    \"\"\"\n",
        "    Endpoint para gestionar el chat.\n",
        "    \"\"\"\n",
        "    data = request.json\n",
        "    user_id = data.get(\"user_id\")\n",
        "    message = data.get(\"message\")\n",
        "\n",
        "    if not user_id or not message:\n",
        "        return jsonify({\"error\": \"user_id y message son requeridos\"}), 400\n",
        "\n",
        "    # Crear o recuperar el contexto del usuario\n",
        "    if user_id not in user_sessions:\n",
        "        user_sessions[user_id] = {\"context\": []}\n",
        "\n",
        "    context = user_sessions[user_id][\"context\"]\n",
        "    full_prompt = f\"Contexto previo: {' '.join(context)}\\nUsuario: {message}\"\n",
        "\n",
        "    # Generar respuesta usando la API de Mistral\n",
        "    response = query_mistral(full_prompt)\n",
        "\n",
        "    # Actualizar el contexto\n",
        "    context.append(message)\n",
        "    user_sessions[user_id][\"context\"] = context\n",
        "\n",
        "    return jsonify({\"response\": response})\n",
        "\n",
        "# Iniciar el servidor\n",
        "def run():\n",
        "    app.run(host=\"0.0.0.0\", port=5002)  # Cambia a un puerto diferente si es necesario\n",
        "\n",
        "# Iniciar el servidor en un hilo para evitar bloqueos\n",
        "thread = Thread(target=run)\n",
        "thread.start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxqVmvz3EU8O",
        "outputId": "ac762a9b-e05d-48be-835d-e34807149608"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingresa tu API key de Mistral: ··········\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5002\n",
            " * Running on http://172.28.0.12:5002\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"http://127.0.0.1:5002/chat\"\n",
        "user_id = \"user123\"\n",
        "\n",
        "while True:\n",
        "    message = input(\"Tú: \")\n",
        "    if message.lower() == \"salir\":\n",
        "        break\n",
        "    response = requests.post(API_URL, json={\"user_id\": user_id, \"message\": message})\n",
        "    if response.status_code == 200:\n",
        "        print(\"Chatbot:\", response.json()[\"response\"])\n",
        "    else:\n",
        "        print(\"Error:\", response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSJ2GrK1EYRO",
        "outputId": "86b499fe-ccb5-4dfb-db21-06a804c9afca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tú: Hola\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Dec/2024 00:24:27] \"POST /chat HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Payload enviado: {'model': 'mistral-7b-v0.1', 'messages': [{'role': 'user', 'content': 'Contexto previo: \\nUsuario: Hola'}], 'max_tokens': 150, 'temperature': 0.7, 'top_p': 1.0}\n",
            "Respuesta completa del error: Sin respuesta del servidor\n",
            "Chatbot: Error al consultar la API de Mistral: 400 Client Error: Bad Request for url: https://api.mistral.ai/v1/chat/completions\n",
            "Tú: Mi nombre es david\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Dec/2024 00:24:36] \"POST /chat HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Payload enviado: {'model': 'mistral-7b-v0.1', 'messages': [{'role': 'user', 'content': 'Contexto previo: Hola\\nUsuario: Mi nombre es david'}], 'max_tokens': 150, 'temperature': 0.7, 'top_p': 1.0}\n",
            "Respuesta completa del error: Sin respuesta del servidor\n",
            "Chatbot: Error al consultar la API de Mistral: 400 Client Error: Bad Request for url: https://api.mistral.ai/v1/chat/completions\n",
            "Tú: salir\n"
          ]
        }
      ]
    }
  ]
}