{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlealo/100profes/blob/master/dlo_template_gradio_demos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducci√≥n a Gradio"
      ],
      "metadata": {
        "id": "s8CImrBc6ueC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio ofrece dos API diferentes seg√∫n el nivel de detalle que se busque:\n",
        "\n",
        "- `gradio.Interface`: API de alto nivel que permite crear demos de ML simplemente proporcionando una lista de entradas y salidas.\n",
        "\n",
        "- `gradio.Blocks`: API de bajo nivel que permite tener un control total sobre los flujos de datos y el dise√±o de la aplicaci√≥n. Se pueden crear aplicaciones muy complejas de varios pasos utilizando Blocks (como si fueran bloques de construcci√≥n).\n",
        "\n",
        "Comenzaremos utilizando `Interface` y al final mostraremos un ejemplo de `Blocks`."
      ],
      "metadata": {
        "id": "ExMhF5WHB_IY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalamos Gradio"
      ],
      "metadata": {
        "id": "BSFxN8lAfwOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "JFek1nvzH3z4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo usando una funci√≥n para saludar que tiene `text` como input y `text` como output."
      ],
      "metadata": {
        "id": "h5EBhuJDgC7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "vptt-bcrfrOx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "b9e0c006-b8b1-464f-a108-7c66bac97fd2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f135166cd8b1959138.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f135166cd8b1959138.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "# Cargar modelo preentrenado MobileNetV2\n",
        "model = tf.keras.applications.MobileNetV2(weights=\"imagenet\")\n",
        "\n",
        "# Descargar las etiquetas de ImageNet\n",
        "labels_url = \"https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\"\n",
        "response = requests.get(labels_url)\n",
        "labels = response.text.split(\"\\n\")[1:]  # la primera l√≠nea es un placeholder \"background\"\n",
        "\n",
        "def classify_image(image):\n",
        "    try:\n",
        "        # Redimensionar y preparar\n",
        "        image = image.resize((224, 224))\n",
        "        img_array = np.asarray(image)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
        "\n",
        "        # Predicci√≥n\n",
        "        preds = model.predict(img_array).flatten()\n",
        "\n",
        "        # Ajustar etiquetas al tama√±o de preds\n",
        "        valid_labels = labels[:len(preds)]\n",
        "\n",
        "        confidences = {valid_labels[i]: float(preds[i]) for i in range(len(preds))}\n",
        "        return confidences\n",
        "    except Exception as e:\n",
        "        print(\"ERROR en classify_image:\", e)\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "\n",
        "# Interfaz Gradio\n",
        "demo = gr.Interface(\n",
        "    fn=classify_image,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Label(num_top_classes=3),\n",
        "    title=\"Clasificador de Im√°genes con MobileNetV2\",\n",
        "    description=\"Sube una imagen y el modelo MobileNetV2 preentrenado en ImageNet la clasificar√°.\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "TsfTLMJbsu9c",
        "outputId": "42683b9d-df5a-473f-ab0d-4912d8a74299"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8befa1311f97d7c31c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8befa1311f97d7c31c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7862 <> https://8befa1311f97d7c31c.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La clase de `gr.Interface` es una forma f√°cil de crear demos que pueden ser desde una calculadora hasta una aplicaci√≥n para reconocimiento de voz.\n",
        "\n",
        "Se inicializa con tres par√°metros necesarios:\n",
        "\n",
        "\n",
        "*   `fn`: la funci√≥n.\n",
        "\n",
        "*   `inputs`: qu√© componente(s) usar para los inputs de la funci√≥n, por ejemplo, \"texto\", \"imagen\" o \"audio\"\n",
        "* `outputs`: qu√© componente(s) usar para los outputs de la funci√≥n, por ejemplo, \"texto\", \"imagen\" o \"etiqueta\"\n",
        "\n",
        "\n",
        "Gradio incluye m√°s de 20 componentes diferentes, la mayor√≠a de los cuales se pueden utilizar como inputs y outputs. En la documentaci√≥n est√° la [lista completa](https://gradio.app/docs/#components)."
      ],
      "metadata": {
        "id": "wkJIvlmtgkfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo 2:"
      ],
      "metadata": {
        "id": "EEgezutgiZ-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "# Cargar modelo de Hugging Face (imagen clasificaci√≥n)\n",
        "classifier = pipeline(\"image-classification\", model=\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "\n",
        "def classify(img):\n",
        "    return classifier(img)\n",
        "\n",
        "titulo = \"Mi primer demo con Hugging Face\"\n",
        "descripcion = \"Una descripci√≥n de mi demo\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=classify,\n",
        "    inputs=gr.Image(label=\"Carga una imagen aqu√≠\"),\n",
        "    outputs=gr.Label(num_top_classes=3),\n",
        "    title=titulo,\n",
        "    description=descripcion\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "9NGKuXXfgLWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3aa508e6-a621-4870-ac1a-607c1519bd9e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://7a01d8f73a6c9c2b8e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7a01d8f73a6c9c2b8e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 626, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 350, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2250, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1757, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 917, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-927192761.py\", line 8, in classify\n",
            "    return classifier(img)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/image_classification.py\", line 189, in __call__\n",
            "    return super().__call__(inputs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 1458, in __call__\n",
            "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 1464, in run_single\n",
            "    model_inputs = self.preprocess(inputs, **preprocess_params)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/image_classification.py\", line 192, in preprocess\n",
            "    image = load_image(image, timeout=timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/image_utils.py\", line 493, in load_image\n",
            "    raise TypeError(\n",
            "TypeError: Incorrect format used for image. Should be an url linking to an image, a base64 string, a local path, or a PIL image.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7862 <> https://c7125906fcde8b9e4e.gradio.live\n",
            "Killing tunnel 127.0.0.1:7863 <> https://7a01d8f73a6c9c2b8e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "\n",
        "# Cargar modelo de Hugging Face\n",
        "classifier = pipeline(\"image-classification\", model=\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "\n",
        "def classify(img):\n",
        "    # Asegurar que sea PIL.Image\n",
        "    if not isinstance(img, Image.Image):\n",
        "        img = Image.fromarray(img)\n",
        "    return classifier(img)\n",
        "\n",
        "titulo = \"Mi primer demo con Hugging Face\"\n",
        "descripcion = \"Una descripci√≥n de mi demo\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=classify,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Carga una imagen aqu√≠\"),  # importante: type=\"pil\"\n",
        "    outputs=gr.Label(num_top_classes=3),\n",
        "    title=titulo,\n",
        "    description=descripcion\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "E8a4Ok6rzsAO",
        "outputId": "32de4fdb-c21f-4c56-d21e-4eeb3e1161ae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a410a5e824efa3b96c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a410a5e824efa3b96c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 626, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 350, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2260, in process_api\n",
            "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2038, in postprocess_data\n",
            "    prediction_value = block.postprocess(prediction_value)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/components/label.py\", line 155, in postprocess\n",
            "    raise ValueError(\n",
            "ValueError: The `Label` output interface expects one of: a string label, or an int label, a float label, or a dictionary whose keys are labels and values are confidences. Instead, got a <class 'list'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7863 <> https://a410a5e824efa3b96c.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "\n",
        "# Cargar modelo de Hugging Face\n",
        "classifier = pipeline(\"image-classification\", model=\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "\n",
        "def classify(img):\n",
        "    # Asegurar que sea PIL.Image\n",
        "    if not isinstance(img, Image.Image):\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "    # Ejecutar el pipeline\n",
        "    results = classifier(img)\n",
        "\n",
        "    # Convertir lista de resultados -> diccionario\n",
        "    confidences = {r[\"label\"]: float(r[\"score\"]) for r in results}\n",
        "    return confidences\n",
        "\n",
        "titulo = \"Mi primer demo con Hugging Face\"\n",
        "descripcion = \"Una descripci√≥n de mi demo\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=classify,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Carga una imagen aqu√≠\"),\n",
        "    outputs=gr.Label(num_top_classes=3),\n",
        "    title=titulo,\n",
        "    description=descripcion\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "lNS8yB9z0PqP",
        "outputId": "91446af2-ae10-407d-96fc-f622bd5a272f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8007becdc1e04c38cd.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8007becdc1e04c38cd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ‚úÖ Explicaci√≥n de la mejora en el demo con Gradio + Hugging Face\n",
        "\n",
        "Cuando conectamos un modelo de **Hugging Face** con **Gradio**, aparecieron varios problemas que fuimos resolviendo paso a paso:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Diferencia entre `labels` y `preds`\n",
        "- **Problema:** El modelo `MobileNetV2` devuelve **1000 probabilidades**, pero el archivo de etiquetas ten√≠a **1001 l√≠neas** (inclu√≠a un `\"background\"` extra).\n",
        "- **Soluci√≥n:** Recortar la lista de etiquetas a **1000 clases reales**:\n",
        "  ```python\n",
        "  labels = response.text.split(\"\\n\")[1:1001]\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Formato de la imagen (`PIL.Image`)\n",
        "- **Problema:** El pipeline de Hugging Face (`pipeline(\"image-classification\")`) esperaba recibir una imagen en formato `PIL.Image`, pero `gr.Image` estaba entregando un `numpy.ndarray`.\n",
        "- **Soluci√≥n:** Configurar Gradio para entregar directamente `PIL.Image`:\n",
        "  ```python\n",
        "  inputs=gr.Image(type=\"pil\")\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Formato de salida esperado por `gr.Label`\n",
        "- **Problema:** El pipeline devolv√≠a una **lista de diccionarios**:\n",
        "  ```python\n",
        "  [\n",
        "    {\"label\": \"Egyptian cat\", \"score\": 0.85},\n",
        "    {\"label\": \"tabby cat\", \"score\": 0.10},\n",
        "    {\"label\": \"tiger cat\", \"score\": 0.04}\n",
        "  ]\n",
        "  ```\n",
        "  Pero `gr.Label` solo acepta:\n",
        "  - un `string`\n",
        "  - un `int` o `float`\n",
        "  - o un **diccionario `{label: probabilidad}`**\n",
        "\n",
        "- **Soluci√≥n:** Convertir la lista en un diccionario:\n",
        "  ```python\n",
        "  results = classifier(img)\n",
        "  confidences = {r[\"label\"]: float(r[\"score\"]) for r in results}\n",
        "  return confidences\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### üîë Resultado final\n",
        "Con estas correcciones:\n",
        "- La interfaz recibe im√°genes como `PIL.Image`.\n",
        "- El modelo Hugging Face procesa correctamente.\n",
        "- El output se transforma en un diccionario comprensible para `gr.Label`.\n",
        "\n",
        "Ahora la demo funciona sin errores üéâ\n"
      ],
      "metadata": {
        "id": "zIBwD-nZ1b-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demos para clasificaci√≥n de im√°genes"
      ],
      "metadata": {
        "id": "kwLrBHxy62Cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 1:** demo con modelo cargado de las aplicaciones de TensorFlow."
      ],
      "metadata": {
        "id": "0XzHJlgVjjWY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4xhcXAn8j4Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Obteniendo las labels de \"https://git.io/JJkYN\"\n"
      ],
      "metadata": {
        "id": "KnIwuuO1kfU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-eK8z_CHUOlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "osfHOsfYUUiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 2**: demo cargando un modelo del Hub de Hugging Face."
      ],
      "metadata": {
        "id": "tBZhxGS1nv7a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XILy1l6dcO7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo de transcripci√≥n de audio a texto"
      ],
      "metadata": {
        "id": "gs4GK4t17dK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos `pipeline` para cargar un modelo para automatic speech recognition en espa√±ol del Hub de Hugging Face.\n",
        "\n",
        "El demo transcribe autom√°ticamente de lo que grabamos."
      ],
      "metadata": {
        "id": "yx57LeGT8BGP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sOjfBWI541e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G7bX5MM7ypJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ssCh6RgW1Kxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blocks"
      ],
      "metadata": {
        "id": "LnTOzNIQ_R2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un demo que recibe dos modelos. Puede transcribir una voz y tambi√©n puede clasificar el sentimiento de un texto."
      ],
      "metadata": {
        "id": "u4JSbah8BjOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rmn5K-zG_S_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XMsS8NZKCwm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFGG0R_CFQkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e2xBXVDAF-5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hagamos un aplicaci√≥n de blocks un poco m√°s interesante."
      ],
      "metadata": {
        "id": "zqK3a-7ygjIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "CHuwCu2m0gmC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}